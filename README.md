# EX-02-Cross-Platform-Prompting-Evaluating-Diverse-Techniques-in-AI-Powered-Text-Summarization

## AIM
To evaluate and compare the effectiveness of prompting techniques (zero-shot, few-shot, chain-of-thought, role-based) across different AI platforms (e.g., ChatGPT, Gemini, Claude, Copilot) in a specific task: text summarization.

## Scenario:
You are part of a content curation team for an educational platform that delivers quick summaries of research papers to undergraduate students. Your task is to summarize a 500-word technical article on "The Basics of Blockchain Technology" using multiple AI platforms and prompting strategies.

Your goal is to determine which combination of prompting technique + platform provides the best summary in terms of:

Accuracy

Coherence

Simplicity

Speed

User experience

## Algorithm
Algorithm: Evaluating Prompting Techniques Across AI Platforms

Input:
  A technical article (~500 words) on "The Basics of Blockchain Technology"
  AI platforms: ChatGPT, Gemini, Claude, Copilot
  Prompting techniques: Zero-shot, Few-shot, Chain-of-Thought, Role-based

Output:
A table showing the best combination of prompting technique + AI platform for each evaluation criterion (Accuracy, Coherence, Simplicity, Speed, User Experience)

Steps:

1.Prepare the Article
Select a technical article (~500 words) suitable for undergraduate students.
Ensure content is neutral, factual, and moderately complex.

2.Define Prompting Techniques
Zero-shot: Direct summarization without examples.
Few-shot: Provide 1–2 example summaries before asking the AI to summarize.
Chain-of-Thought: Ask the AI to reason step by step before generating a summary.
Role-based: Ask the AI to assume the role of a professional content curator.

3.Design Evaluation Criteria
Accuracy: Correctness of key points.
Coherence: Logical flow and readability.
Simplicity: Understandable by undergraduate students.
Speed: Response time.
User Experience: Ease of interaction and output formatting.

4.Execute Summarization
For each AI platform:
  For each prompting technique:
    1.Input the article using the chosen prompt.
    2.Record the summary output.
    3.Note the response time.
    4.Record any observations regarding user experience.

5.Evaluate Outputs
Score each summary on all evaluation criteria (e.g., 1–5 scale).
Optionally, use multiple evaluators to reduce bias.

6.Compile Results
Create a table with columns: Goal, Best Prompting Technique, Best AI Platform, Reasoning.
Fill in the table based on which combination scored highest for each criterion.

7.Analyze Patterns
Identify which prompting techniques and platforms excel in specific goals.
Note any trade-offs (e.g., fastest output may not be most accurate).
Determine if any combination is overall the best.

8.Conclude
Summarize findings: Recommend the optimal combination of prompting technique + AI platform for your task.

## Output
![image alt](https://github.com/SZESRIRAM/EX-02-Cross-Platform-Prompting-Evaluating-Diverse-Techniques-in-AI-Powered-Text-Summarization/blob/main/EXP%202.png?raw=true)

## Result
This experiment shows how prompting techniques and AI platforms affect text summarization. It highlights the best combinations for accuracy, coherence, simplicity, speed, and user experience. Overall, choosing the right prompt and platform is key to producing clear, accurate, and student-friendly summaries.


